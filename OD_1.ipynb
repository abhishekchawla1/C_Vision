{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fdb5975",
   "metadata": {},
   "source": [
    "Object Detection"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f875f7d",
   "metadata": {},
   "source": [
    "input = image\n",
    "output =  object present inside an image and also the class to which it belongs to\n",
    "\n",
    "Classification vs Localization vs Detection\n",
    "\n",
    "alexnet,vgg,resnet - image classification models\n",
    "2014-RCNN (Best architecture for Object Detection)\n",
    "\n",
    "object detection is part of CV where we not only classify an image, we predict the class of the image and draw a bounding box accordingly.\n",
    "\n",
    "Image Classification: given an image if we can predict the label, its classification.\n",
    "\n",
    "Localization: Only considering one object of an image.\n",
    "\n",
    "Image Detection or OD: detects all the objects and all classes and all the bounding boxes in a given image irrespective of image's shape and size.\n",
    "\n",
    "Flatten? Vectorization of an image\n",
    "\n",
    "BB? BB should be predicted by the model. How? \n",
    "\n",
    "locate the centre and get the coordinates along with width and height.\n",
    "idea: to have the bounding boox as close to the object as possibe.\n",
    "\n",
    "COCO bounding box representation: we get top left coordinats along with height ad width.\n",
    "YOLO bounding box representation: we get centre along with width and height.\n",
    "\n",
    "Ground Truth: As a person I can draw a box around an object. Thats ground truth.\n",
    "\n",
    "Modification in CNN architecture such that object detection can be performed.\n",
    "\n",
    "AlexNet ---> Flatten ---->Extend the architecture such that x,y,w,h are noted and used which is then trained on a regression model.\n",
    "Drawback: Multiple objects in a frame such that each object can be bounded in a BB.\n",
    "This algo fails.\n",
    "rectification: SLiding Window\n",
    "\n",
    "Sliding Window Approach\n",
    "\n",
    "Image ---- 224,224 and kernel is 3,3. Kernel is iterated and every small image segment is checked. \n",
    "\n",
    "each segment is sent to a CNN architecture and we classify it as a background or object. CNN- classes+1number of outputs.\n",
    "multiple boxes with multiple aspect ratio and is sent to CNN Classifier.\n",
    "Prob: Every object is not of similar space. Millions of boxes due to objects, to overcome this RCNNNs are used. To dec no of bounding boxes and to fasten training.\n",
    "\n",
    "Region Convolution Neural Networks. Reduces the number of bounding boxes.\n",
    "MAKE GROUND TRUTHS AND TRAIN THE MOEDL\n",
    "\n",
    "Dec the no of regions to be passes in CNN. \n",
    "Selective Search : takes input as an image and gives bounding boxes as output which has high probability of containing an object.\n",
    "\n",
    "Segments image into regions.\n",
    "Merge similar regions to create larger regions. \n",
    "\n",
    "RCNN\n",
    "\n",
    "3 modules: 1 - generates categories which is category independent.\n",
    "Mapping and coloring, it takes million of points and classify the segments on the basis of color, texture, shape, size and linear combination of all the things.\n",
    "\n",
    "Merges similar regions based on pixel values : Selective Search\n",
    "algo which understands what is hapenning inside an image.\n",
    "It gives 2000 boxes with high probability that there is an image present inside it.\n",
    "\n",
    "crop these regions and pass these inputs through an AlexNet architecture, we dont not know what class they belong to! How to label these boxes? \n",
    "alexnet as architecture will take 224x224 size but bounding boxes are of varous sizes so reshaping of image is done and then padding is done p = 16 is the best number that worked.\n",
    "\n",
    "Labeling?\n",
    "IOU score=Intersection Area/Union Area\n",
    "\n",
    "Calculates the values and value resonates between 0 and 1.\n",
    "If IOU>0.5 we keep the box and filter the rest out, we get an image with limited bb. This is the final bb image whch will be passes to the model which increases efficiency.\n",
    "\n",
    "If a proposal box overlaps two regions with IOU>0.5 then that box is selected whose IOU value is greater, ie that label is used."
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff4b3936",
   "metadata": {},
   "source": [
    "-ve class : IOU <0.3"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e4b515cc",
   "metadata": {},
   "source": [
    "input with group truth --- selective search --- 2000 BB images --- +ve images IOU>0.5 --- -ve images IOU<0.3 --- We train these on SVM for num of classes to understand if object is present in the region or not. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "ad97d21c",
   "metadata": {},
   "source": [
    "Bounding Box regressor:\n",
    "\n",
    "Input with labels and ground truth with coordinates.\n",
    "Selective Search gives a bb so transformations need to be done which turns the region into ideal bb.\n",
    "CNN with 4 dense layers and regresoor which are aving IOu values > 0.6. ML model is trained on this ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39184e0",
   "metadata": {},
   "source": [
    "RCNN : Convolutional Neural Netowrks , SVM , BB Regressor\n",
    "Ground truth hai\n",
    "selective search ne batadia unideal box\n",
    "dono ko match krne ke lie tweak krna pdega. \n",
    "ML model banaenge\n",
    "Regresson task perform krenge best idal box laenge."
   ]
  },
  {
   "cell_type": "raw",
   "id": "33472329",
   "metadata": {},
   "source": [
    "You need to know the no of object to be predicted before hand."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f5f130c5",
   "metadata": {},
   "source": [
    "NonMax Supression:\n",
    "\n",
    "model gives 3 boxes with person, all three have high probability, one and only box is required. Non Max Supression is applied. Cnn har box pe predictkrta hai.\n",
    "NMS is applied to each object.\n",
    "\n",
    "B1- prob 0.7\n",
    "b2- prob 0.8\n",
    "b3- 0.9\n",
    "\n",
    "we keep only b3\n",
    "IOU score and Pobability are high then discard others\n",
    "Keep the maximum and discard the others."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c133741",
   "metadata": {},
   "source": [
    "Flow:\n",
    "\n",
    "Extract the bb using selective search\n",
    "Trian VGG on Imagenet dataset\n",
    "fine tune cnn with resized proposals on classes of detectiondatasetand background class.\n",
    "Train binary classifiers (SVM) for each class on fully connected layer representation of proposlas.\n",
    "train a class specific bb regressor on top of proposal features.\n",
    "Filter the predictions using Non max Suppression."
   ]
  },
  {
   "cell_type": "raw",
   "id": "bd23573c",
   "metadata": {},
   "source": [
    "Evaluation Metrics:\n",
    "\n",
    "IOU = Intersection Area/Union Area\n",
    "map - mean average precision\n",
    "TP, FP, FN ----- precision and recall are calculated\n",
    "sahi prediction/ prediction total -- precision\n",
    "sahi prediction/total ground truths - recall\n",
    "\n",
    "MAP\n",
    "4 predction \n",
    "3 ground truth\n",
    "\n",
    "Sort bb on the basis of prob score and IOU score.\n",
    "PR CURVE banado\n",
    "\n",
    "area unde pr curve is average precision\n",
    "no of classes = 2\n",
    "1st class-----area\n",
    "2nd class-----area\n",
    "dono k area ka mean == map\n",
    "only taking those regions whose IOC>0.5\n",
    "threshold is taken different and every value is taken and mean is taken and that is our mean average precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156abc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
